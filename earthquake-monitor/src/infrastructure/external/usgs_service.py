"""USGS earthquake data ingestion service."""

import json
import logging
from datetime import UTC, datetime

import httpx

from src.domain.entities.earthquake import Earthquake
from src.domain.entities.location import Location
from src.domain.entities.magnitude import Magnitude, MagnitudeScale

logger = logging.getLogger(__name__)


class USGSService:
    """Service for fetching earthquake data from USGS GeoJSON feeds."""

    def __init__(self):
        self.base_url = "https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary"
        self.client = httpx.AsyncClient(timeout=30.0)

    async def close(self):
        """Close HTTP client."""
        await self.client.aclose()

    async def fetch_recent_earthquakes(
        self, period: str = "day", magnitude: str = "all"
    ) -> list[Earthquake]:
        """
        Fetch recent earthquakes from USGS.

        Args:
            period: Time period ('hour', 'day', 'week', 'month')
            magnitude: Magnitude filter ('all', 'significant', '4.5', '2.5', '1.0')

        Returns:
            List of Earthquake entities
        """
        try:
            url = f"{self.base_url}/{magnitude}_{period}.geojson"
            logger.info(f"Fetching earthquakes from USGS: {url}")

            response = await self.client.get(url)
            response.raise_for_status()

            data = response.json()
            earthquakes = []

            for feature in data.get("features", []):
                try:
                    earthquake = self._parse_earthquake_feature(feature)
                    if earthquake:
                        earthquakes.append(earthquake)
                except Exception as e:
                    logger.warning(f"Failed to parse earthquake feature: {e}")
                    continue

            logger.info(
                f"Successfully fetched {len(earthquakes)} earthquakes from USGS"
            )
            return earthquakes

        except httpx.HTTPError as e:
            logger.error(f"HTTP error fetching USGS data: {e}")
            raise
        except Exception as e:
            logger.error(f"Error fetching USGS data: {e}")
            raise

    def _parse_earthquake_feature(self, feature: dict) -> Earthquake | None:
        """Parse a GeoJSON feature into an Earthquake entity."""
        try:
            properties = feature.get("properties", {})
            geometry = feature.get("geometry", {})
            coordinates = geometry.get("coordinates", [])

            if len(coordinates) < 3:
                logger.warning("Invalid coordinates in earthquake feature")
                return None

            # Extract basic data
            longitude, latitude, depth = coordinates[0], coordinates[1], coordinates[2]
            magnitude_value = properties.get("mag")
            occurred_at_timestamp = properties.get("time")

            if magnitude_value is None or occurred_at_timestamp is None:
                logger.warning("Missing required earthquake data")
                return None

            # Validate and clean data
            if magnitude_value < 0:
                logger.warning(
                    f"Invalid negative magnitude: {magnitude_value}, skipping"
                )
                return None

            if depth is not None and depth < 0:
                logger.warning(f"Invalid negative depth: {depth}, setting to 0")
                depth = 0.0

            # Convert timestamp to datetime
            occurred_at = datetime.fromtimestamp(
                occurred_at_timestamp / 1000, UTC  # USGS uses milliseconds
            )

            # Create domain entities
            location = Location(
                latitude=float(latitude),
                longitude=float(longitude),
                depth=float(depth) if depth is not None else 0.0,
            )

            # Determine magnitude scale (USGS typically uses moment magnitude)
            magnitude_type = properties.get("magType", "mw")
            if magnitude_type.lower() in ["mw", "mww", "mwc", "mwr"]:
                scale = MagnitudeScale.MOMENT
            elif magnitude_type.lower() in ["ml", "ml_"]:
                scale = MagnitudeScale.RICHTER
            else:
                scale = MagnitudeScale.MOMENT  # Default

            magnitude = Magnitude(value=float(magnitude_value), scale=scale)

            # Create earthquake entity
            earthquake = Earthquake(
                location=location,
                magnitude=magnitude,
                occurred_at=occurred_at,
                source="USGS",
                # Note: earthquake_id will be auto-generated by the entity
            )

            # Add USGS-specific data
            earthquake.external_id = properties.get("id")
            earthquake.raw_data = json.dumps(feature)

            # Additional USGS properties we might want to store
            earthquake.place = properties.get("place")
            earthquake.url = properties.get("url")
            earthquake.detail_url = properties.get("detail")
            earthquake.status = properties.get("status")
            earthquake.tsunami = properties.get("tsunami", 0)
            earthquake.significance = properties.get("sig")
            earthquake.alert = properties.get("alert")
            earthquake.cdi = properties.get("cdi")  # Community Did You Feel It
            earthquake.mmi = properties.get("mmi")  # Modified Mercalli Intensity

            return earthquake

        except Exception as e:
            logger.error(f"Error parsing earthquake feature: {e}")
            return None

    async def fetch_earthquake_details(self, usgs_id: str) -> dict | None:
        """
        Fetch detailed information for a specific earthquake.

        Args:
            usgs_id: USGS earthquake ID

        Returns:
            Detailed earthquake data
        """
        try:
            url = (
                f"https://earthquake.usgs.gov/earthquakes/eventpage/{usgs_id}/executive"
            )
            response = await self.client.get(url)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Error fetching earthquake details for {usgs_id}: {e}")
            return None

    async def get_available_feeds(self) -> dict:
        """Get information about available USGS earthquake feeds."""
        feeds = {
            "real_time": {
                "significant_month": f"{self.base_url}/significant_month.geojson",
                "significant_week": f"{self.base_url}/significant_week.geojson",
                "significant_day": f"{self.base_url}/significant_day.geojson",
                "significant_hour": f"{self.base_url}/significant_hour.geojson",
                "m4.5_month": f"{self.base_url}/4.5_month.geojson",
                "m4.5_week": f"{self.base_url}/4.5_week.geojson",
                "m4.5_day": f"{self.base_url}/4.5_day.geojson",
                "m4.5_hour": f"{self.base_url}/4.5_hour.geojson",
                "m2.5_month": f"{self.base_url}/2.5_month.geojson",
                "m2.5_week": f"{self.base_url}/2.5_week.geojson",
                "m2.5_day": f"{self.base_url}/2.5_day.geojson",
                "m2.5_hour": f"{self.base_url}/2.5_hour.geojson",
                "m1.0_month": f"{self.base_url}/1.0_month.geojson",
                "m1.0_week": f"{self.base_url}/1.0_week.geojson",
                "m1.0_day": f"{self.base_url}/1.0_day.geojson",
                "m1.0_hour": f"{self.base_url}/1.0_hour.geojson",
                "all_month": f"{self.base_url}/all_month.geojson",
                "all_week": f"{self.base_url}/all_week.geojson",
                "all_day": f"{self.base_url}/all_day.geojson",
                "all_hour": f"{self.base_url}/all_hour.geojson",
            }
        }
        return feeds
